# Wright_CSCI2270_FinalProject

For my project I plan on creating sets of weighted and undirected graphs in which I will find the shortest path between two verticies. I will track the number of processes each algorithm takes to complete and record this data within a linked list and binary search tree. I will then comment on which algorithms are more effective in specific situations (The two verticies are close  together, the two verticies are far apart, etc) or are more effective overall. I will also comment on the processing requirement  of traversing my linked list and my binary search tree that store the data to see which is more effective for storing data to be used in analysis (Considering operations such as alphabetical printing, specifc item searching, etc).

A secondary goal if possible to implement within the time given to complete the project will be to randomly generate the data within the graphs. If implemented I will create an arbitrary but large amount of data sets, between 20 and 60. Each data  set will contain a number of verticies with  fixed values (A, B, C,...) but the number of verticies will be random. For example if the number of verticies is chosen to be 4 the values will be A B C D, if the number of verticies is 6 the values of the verticies will be A B C D E F. The weight of each edge will be randomly generated, which verticies are connected will also be randomly generated. The verticies selected to have a shortest path found between will also be randomly selected. Within a set of A B C D E I will have the program randomly select which verticies are connected, A connected to B, C, and D, B connected to A, C, etc, and the weights between each connection will be random but within a set range, between 1 and 100 for example, and the program will choose two points to have a path found between, so the shortest path between B and E is a possible selection in this example. I believe this will create more interesting and less artifical results, especially if I generate a large amount of data sets.

The primary goal will still be analyzing each algorithm's performance and looking at the context of the graph (Connections between the two verticies in the final shortest path, number of verticies, etc) and finding an efficient means of storing this data to be quickly analzyed. If I finish my primary goal and am satisfied with its performance I will implement as much of my secondary goal as possible because I believe the results of random data will be more authentic and interesting. If I am unable to implement my secondary goal my plan will be to manually create graphs for my program to analyze.
